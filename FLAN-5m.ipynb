{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### System Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# System Messages\n",
    "# Page 9, Table 2\n",
    "SM = {\n",
    "    1: \"\",\n",
    "    2: \"You are an AI assistant. Provide a detailed answer so user don’t need to search outside to understand the answer.\",\n",
    "    3: \"You are an AI assistant. You will be given a task. You must generate a detailed and long answer.\",\n",
    "    4: \"You are a helpful assistant, who always provide explanation. Think like you are answering to a five year old.\",\n",
    "    5: \"You are an AI assistant that follows instruction extremely well. Help as much as you can.\",\n",
    "    6: \"You are an AI assistant that helps people find information. Provide a detailed answer so user don’t need to search outside to understand the answer.\",\n",
    "    7: \"You are an AI assistant. User will you give you a task. Your goal is to complete the task as faithfully as you can. While performing the task think step-by-step and justify your steps.\",\n",
    "    8: \"You should describe the task and explain your answer. While answering a multiple choice question, first output the correct answer(s). Then explain why other answers are wrong. Think like you are answering to a five year old.\",\n",
    "    9: \"Explain how you used the definition to come up with the answer.\",\n",
    "    10: \"You are an AI assistant. You should describe the task and explain your answer. While answering a multiple choice question, first output the correct answer(s). Then explain why other answers are wrong. You might need to use additional knowledge to answer the question.\",\n",
    "    11: \"You are an AI assistant that helps people find information. User will you give you a question. Your task is to answer as faithfully as you can. While answering think step-bystep and justify your answer.\",\n",
    "    12: \"User will you give you a task with some instruction. Your job is follow the instructions as faithfully as you can. While answering think step-by-step and justify your answer.\",\n",
    "    13: \"You are a teacher. Given a task, you explain in simple steps what the task is asking, any guidelines it provides and how to use those guidelines to find the answer.\",\n",
    "    14: \"You are an AI assistant, who knows every language and how to translate one language to another. Given a task, you explain in simple steps what the task is asking, any guidelines that it provides. You solve the task and show how you used the guidelines to solve the task.\",\n",
    "    15: \"Given a definition of a task and a sample input, break the definition into small parts.\\nEach of those parts will have some instruction. Explain their meaning by showing an example that meets the criteria in the instruction. Use the following format:\\nPart  # : a key part of the definition.\\nUsage: Sample response that meets the criteria from the key part. Explain why you think it meets the criteria.\",\n",
    "    16: \"You are an AI assistant that helps people find information.\",\n",
    "}\n",
    "\n",
    "# System Message Pickers \n",
    "# Figure 6 page 10\n",
    "sm_cot = lambda: SM[random.choice([6, 11, 16])]\n",
    "sm_niv2 = lambda: SM[random.choice([1, 2, 5, 7, 9, 12, 13, 14, 15])]\n",
    "sm_t0 = lambda: SM[random.choice([1, 2, 3, 5, 7])]\n",
    "sm_flan2021 = lambda multiple_choice: SM[random.choice([8, 10])] if multiple_choice else SM[random.choice([3, 4, 7])]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_dataset(dataset_name):\n",
    "    if dataset_name.lower() == \"cot\":\n",
    "        cot = iter(datasets.load_dataset(\"conceptofmind/cot_submix_original\", streaming=True))\n",
    "        process_cot(cot)\n",
    "    elif dataset_name.lower() == \"niv\":\n",
    "        niv = iter(datasets.load_dataset(\"conceptofmind/niv2_submix_original\", streaming=True))\n",
    "        process_niv(niv)\n",
    "    elif dataset_name.lower() == \"flan\":\n",
    "        flan = iter(datasets.load_dataset(\"conceptofmind/flan2021_submix_original\", streaming=True))\n",
    "        process_flan(flan)\n",
    "    elif dataset_name.lower() == \"t0\":\n",
    "        t0 = iter(datasets.load_dataset(\"conceptofmind/t0_submix_original\", split=\"train\", streaming=True))\n",
    "        process_t0(t0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\entropi\\mambaforge\\envs\\oo\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import datasets\n",
    "import tqdm\n",
    "from check_if_multiple_choice import check_if_multiple_choice\n",
    "\n",
    "# Table 3 Page 10\n",
    "cot_total = 150000\n",
    "niv_total = 440000\n",
    "flan_total = 2500000\n",
    "t0_total = 2000000"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CoT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"COT\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "cot = iter(datasets.load_dataset(\n",
    "    \"conceptofmind/cot_submix_original\", streaming=True))\n",
    "\n",
    "def process_cot(cot):\n",
    "    with open(\"data/cot.jsonl\", \"w\") as f:\n",
    "        stream = tqdm.tqdm(cot, total=cot_total)\n",
    "        \n",
    "        for i, data in enumerate(stream):\n",
    "            print(f\"Data at index {i}: {data}\")\n",
    "            print(f\"Type of data at index {i}: {type(data)}\")\n",
    "            if data['template_type'] not in ['zs_opt', 'zs_noopt']:\n",
    "               continue\n",
    "            \n",
    "            question = data['inputs']\n",
    "            system_prompt = sm_cot()\n",
    "            json.dump({\"id\": f\"cot.{i}\", \"messages\": [{\"role\": \"system\", \"content\": system_prompt}, {\"role\": \"user\", \"content\": question}]}, f)\n",
    "            f.write(\"\\n\")\n",
    "            \n",
    "            stream.update(i)\n",
    "            if i >= cot_total:\n",
    "                break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NIV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "niv = iter(datasets.load_dataset(\n",
    "    \"conceptofmind/niv2_submix_original\", streaming=True))\n",
    "\n",
    "\n",
    "def process_niv(niv):\n",
    "    with open(\"data/niv.jsonl\", \"w\") as f:\n",
    "        stream = tqdm.tqdm(niv, total=niv_total)\n",
    "        task_counts = {}\n",
    "        \n",
    "        for i, data in enumerate(stream):\n",
    "            task_id = data['task_id']\n",
    "            task_counts.setdefault(task_id, 0)\n",
    "            \n",
    "            if task_counts[task_id] < 300:\n",
    "                question = data['inputs']\n",
    "                system_prompt = sm_niv2()\n",
    "                json.dump({\"id\": f\"niv.{i}\", \"messages\": [{\"role\": \"system\", \"content\": system_prompt}, {\"role\": \"user\", \"content\": question}]}, f)\n",
    "                f.write(\"\\n\")\n",
    "                \n",
    "                task_counts[task_id] += 1\n",
    "                \n",
    "            stream.update(i)\n",
    "            if i >= niv_total:\n",
    "                break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FLAN2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "flan = iter(datasets.load_dataset(\n",
    "    \"conceptofmind/flan2021_submix_original\", streaming=True))\n",
    "\n",
    "def sample_queries(tasks, n, max_queries_per_task=1000000):\n",
    "    Q = []\n",
    "    while len(Q) < n:\n",
    "        t = random.choice(tasks)\n",
    "        if not t or len(t) >= max_queries_per_task:\n",
    "            tasks.remove(t)\n",
    "            continue\n",
    "        q = random.choice(t)\n",
    "        t.remove(q)\n",
    "        Q.append(q)\n",
    "    return Q\n",
    "\n",
    "def process_flan(flan):\n",
    "    tasks = {}\n",
    "    for data in flan:\n",
    "        task_id = data['task_id']\n",
    "        if task_id not in tasks:\n",
    "            tasks[task_id] = []\n",
    "        tasks[task_id].append(data)\n",
    "\n",
    "    sampled_queries = sample_queries(list(tasks.values()), flan_total)\n",
    "\n",
    "    with open(\"data/flan.jsonl\", \"w\") as f:\n",
    "        stream = tqdm.tqdm(sampled_queries, total=flan_total)\n",
    "        \n",
    "        for i, data in enumerate(stream):\n",
    "            question = data['inputs']\n",
    "            multiple_choice = check_if_multiple_choice(question)\n",
    "            system_prompt = sm_flan2021(multiple_choice)\n",
    "            json.dump({\"id\": f\"flan.{i}\", \"messages\": [{\"role\": \"system\", \"content\": system_prompt}, {\"role\": \"user\", \"content\": question}]}, f)\n",
    "            f.write(\"\\n\")\n",
    "            \n",
    "            stream.update(i)\n",
    "            if i >= flan_total:\n",
    "                break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T0 Submix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0_total = 2000000\n",
    "\n",
    "T0 = iter(datasets.load_dataset(\n",
    "    \"conceptofmind/t0_submix_original\", split=\"train\", streaming=True))\n",
    "\n",
    "def process_t0(t0):\n",
    "    tasks = {}  \n",
    "    for data in t0:\n",
    "        task_id = data['task_id']\n",
    "        if \"big-bench\" not in task_id.lower():\n",
    "            if task_id not in tasks:\n",
    "                tasks[task_id] = []\n",
    "            tasks[task_id].append(data)\n",
    "\n",
    "    sampled_queries = sample_queries(list(tasks.values()), t0_total)\n",
    "\n",
    "    with open(\"data/t0.jsonl\", \"w\") as f:\n",
    "        stream = tqdm.tqdm(sampled_queries, total=t0_total)\n",
    "        \n",
    "        for i, data in enumerate(stream):\n",
    "            question = data['inputs']\n",
    "            system_prompt = sm_t0()\n",
    "            json.dump({\"id\": f\"t0.{i}\", \"messages\": [{\"role\": \"system\", \"content\": system_prompt}, {\"role\": \"user\", \"content\": question}]}, f)\n",
    "            f.write(\"\\n\")\n",
    "            \n",
    "            stream.update(i)\n",
    "            if i >= t0_total:\n",
    "                break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Please choose a dataset to download and process:\")\n",
    "print(\"1. COT\")\n",
    "print(\"2. NIV\")\n",
    "print(\"3. FLAN\")\n",
    "print(\"4. T0\")\n",
    "\n",
    "dataset_options = {\n",
    "    \"1\": \"cot\",\n",
    "    \"2\": \"niv\",\n",
    "    \"3\": \"flan\",\n",
    "    \"4\": \"t0\",\n",
    "}\n",
    "\n",
    "selected_option = input(\"Enter the corresponding digit: \")\n",
    "\n",
    "download_dataset(dataset_options[selected_option])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
